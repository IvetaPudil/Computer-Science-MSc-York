{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8604ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import statistics\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, filedialog, messagebox, scrolledtext\n",
    "from tabulate import tabulate\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_tkagg import FigureCanvasTkAgg\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd698d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  For any future work , you can :  (w.a :  +923186190858) & (em: afiatiq1@gmail.com) :) Thanks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a81309",
   "metadata": {},
   "source": [
    "# Create the main application window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e91c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = tk.Tk()\n",
    "window.title('Data Analysis System')\n",
    "window.geometry('1400x720')\n",
    "# window.resizable(False, False)\n",
    "window.config(bg='gray20')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df5f77a",
   "metadata": {},
   "source": [
    "# Loading both files: TxParamsDAB & TxAntennaDAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0de87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# global vars\n",
    "counter =0 \n",
    "df1 = pd.DataFrame()\n",
    "df2 =  pd.DataFrame()\n",
    "# Function to load CSV files\n",
    "def load_csv_files():\n",
    "    global df1, df2 \n",
    "    global counter\n",
    "    file1 = filedialog.askopenfilename(title=\"Select TxParamsDAB file\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "    file2 = filedialog.askopenfilename(title=\"Select TxAntennaDAB file\", filetypes=[(\"CSV files\", \"*.csv\")])\n",
    "\n",
    "    if file1 and file2:\n",
    " \n",
    "        df1 = pd.read_csv(file1, encoding='ISO-8859-1')\n",
    "        df2 = pd.read_csv(file2, encoding='ISO-8859-1')\n",
    "        messagebox.showinfo(title='Message', message='Files are successfully loaded!')\n",
    "        counter = 1\n",
    "    else:\n",
    "        messagebox.showerror(title='Error', message='An unexpected error occurs!')\n",
    "        counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8acb228",
   "metadata": {},
   "source": [
    "# Show initial data of both Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2008949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show initial data of both Files\n",
    "def display_files():\n",
    "    global counter\n",
    "    if counter == 1:\n",
    "        text_area1.delete(1.0, tk.END)  # Clear existing text\n",
    "        text_area1.insert(tk.END, df1.head(50).to_string(index=False))\n",
    "        \n",
    "        text_area2.delete(1.0, tk.END)  # Clear existing text\n",
    "        text_area2.insert(tk.END, df2.head(50).to_string(index=False))\n",
    "    else:\n",
    "        messagebox.showerror(title='Error', message='Files are not loaded!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b28c097",
   "metadata": {},
   "source": [
    "# Show cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b413c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_data():\n",
    "    # DF1 column names and data types\n",
    "    global counter\n",
    "    if counter == 1:\n",
    "        global df1\n",
    "        global df2\n",
    "        column_summary = []\n",
    "\n",
    "        for col in df1.columns:\n",
    "            dtype = df1[col].dtype\n",
    "            non_null_count = df1[col].count()\n",
    "            column_summary.append((col, dtype, non_null_count))\n",
    "\n",
    "        # Summary list converted to a DataFrame for printing\n",
    "        summary_df1 = pd.DataFrame(column_summary, columns=['Column Name', 'Data Type', 'Non-Null Count'])\n",
    "        #summary_df1.head(3)\n",
    "        # summary_df1[61:121]\n",
    "        # Check if a column has unique values\n",
    "        duplicates = df1[df1['id'].duplicated(keep=False)]\n",
    "        #print('--------------> Duplicates in Df-1')\n",
    "        #print(duplicates)\n",
    "        # Determine and drop empty columns \n",
    "        empty_columns = df1.columns[df1.isnull().all()]\n",
    "\n",
    "        df1 = df1.drop(empty_columns, axis=1)\n",
    "\n",
    "        #df1.info()\n",
    "        # Convert 'Date' column (#1) from an object to a datetype datatype\n",
    "        df1[\"Date\"] = pd.to_datetime(df1[\"Date\"], format = '%d/%m/%Y')\n",
    "\n",
    "        #print(df1.dtypes)\n",
    "        # remove space at end of 'Serv Label[no]' columns\n",
    "        column_names = df1.columns.tolist()\n",
    "\n",
    "        # iterate through column names\n",
    "        for col_name in column_names:\n",
    "            if col_name.startswith('Serv Label'):\n",
    "                new_col_name = col_name.rstrip() \n",
    "                df1.rename(columns={col_name: new_col_name}, inplace = True)\n",
    "        # In Serv Label1 Change 'Forth One' to \"Forth 1\"\n",
    "        df1['Serv Label1'] = df1['Serv Label1'].str.replace('One', '1')\n",
    "        # Fix capitalisation in columns 'Transmitter Area'. Keep lowercase if it's \"and\" or \"of\". Keep \"UK\" capitalized?\n",
    "        def custom_title(s):\n",
    "            words = s.split()\n",
    "            for i, word in enumerate(words):\n",
    "                if i == 0 or word.lower() not in [\"and\", \"of\"]:\n",
    "                    words[i] = word.capitalize()\n",
    "                # elif word == \"UK\":\n",
    "                #     words[i] = \"UK\"\n",
    "            return ' '.join(words)\n",
    "\n",
    "        df1['Transmitter Area'] = df1['Transmitter Area'].apply(custom_title)\n",
    "        #df1.head(3)\n",
    "        # Fix capitalisation in column 'Site'. Keep lowercase if it's \"and\" or \"of\". \n",
    "        df1['Site'] = df1['Site'].apply(custom_title)\n",
    "        #df1.head()\n",
    "        # Fix capitalisation in columns 'Serv Label1'. \n",
    "        df1['Serv Label1'] = df1['Serv Label1'].apply(lambda x: custom_title(x) if pd.notna(x) else x)\n",
    "        # Fix capitalisation in columns 'Serv Label2'. \n",
    "        df1['Serv Label2'] = df1['Serv Label2'].apply(lambda x: custom_title(x) if pd.notna(x) else x)\n",
    "        # Fix capitalisation in columns 'Serv Label4'. \n",
    "        df1['Serv Label4'] = df1['Serv Label4'].apply(lambda x: custom_title(x) if pd.notna(x) else x)\n",
    "        #df1.head()\n",
    "        # Break up DF1 into separate tables as per entity-relationship diagram to reduce redundancy\n",
    "        # Green table = ensemble, ensemble area, license (and EID, frequency, block, service labels, SLDs, LSNs?)\n",
    "\n",
    "        # List of column names to be removed\n",
    "        columns_to_remove = [\"Ensemble\", \"Licence\", \"Ensemble Area\"]\n",
    "\n",
    "        # new DataFrame 'ensemble_df' containing the removed columns\n",
    "        ensemble_df = df1[columns_to_remove]\n",
    "        #ensemble_df.head()\n",
    "        # remove selected columns from df1\n",
    "        df1 = df1.drop(columns_to_remove, axis=1)\n",
    "        # print('\\nDF-1 after Data Cleaning & Tronsformation :')\n",
    "        # print(df1.head(5))\n",
    "        # --------------->.. DF 2 section \n",
    "        ## 1.3. DF2\n",
    "        # DF2 inspect headings\n",
    "        # df2.head()\n",
    "        # DF2 column names and data types\n",
    "        # df2.info()\n",
    "        # Check if id column has unique values\n",
    "        duplicates = df2[df2['id'].duplicated(keep=False)]\n",
    "        # print('--------------> Duplicates in Df-2')\n",
    "        # print(duplicates)\n",
    "        # drop Longitude/Latitude column (#2), \n",
    "        # because this information is repeated in columns Lat (#43) and Long (#44) where it is correctly formatted \n",
    "        df2 = df2.drop(columns=['Longitude/Latitude'])\n",
    "\n",
    "        #print(df2)\n",
    "\n",
    "        # remove commas in column 'In-Use ERP TotalP' (#4) and convert it to a float\n",
    "        df2['In-Use ERP Total'] = df2['In-Use ERP Total'].str.replace(',', '').astype(float)\n",
    "        #df2.info()\n",
    "        # Add prefix \"col_\" prefix to columns 6 to 41\n",
    "\n",
    "        columns_to_rename = df2.columns[6:42]\n",
    "\n",
    "        # dictionary to store the mapping of old names to new names\n",
    "        rename_dict = {col: f\"col_{col}\" for col in columns_to_rename}\n",
    "\n",
    "        df2 = df2.rename(columns=rename_dict)\n",
    "        #df2.info()\n",
    "        # print('\\nDF-2 after Data Cleaning & Tronsformation :')\n",
    "        # print(df2.head(5))\n",
    "\n",
    "\n",
    "        text_area1.delete(1.0, tk.END)  # Clear existing text\n",
    "        text_area1.insert(tk.END, df1.head(50).to_string(index=False))\n",
    "        text_area2.delete(1.0, tk.END)  # Clear existing text\n",
    "        text_area2.insert(tk.END, df2.head(50).to_string(index=False))\n",
    "\n",
    "    else:\n",
    "        messagebox.showerror(title='Error', message='Files are not loaded!')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34907330",
   "metadata": {},
   "source": [
    "# Show Merged Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875ed367",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merged_df =  pd.DataFrame()\n",
    "def merge_data():\n",
    "    \n",
    "    global counter\n",
    "    if counter == 1:\n",
    "        global merged_df\n",
    "        # merge df1 and df2 using 'id' column\n",
    "        merged_df = df1.merge(df2, on='id')\n",
    "        df1_lbl.destroy()\n",
    "        df2_lbl.destroy()\n",
    "        text_area1.destroy()\n",
    "        text_area2.destroy()\n",
    "        horizontal_scrollbar1.destroy()\n",
    "        horizontal_scrollbar2.destroy()\n",
    "        middle_frame.destroy()\n",
    "\n",
    "        # --> Middle Frame\n",
    "        right_frame = tk.LabelFrame(frame,text='',bg='gray20')\n",
    "        right_frame.grid(row=0, column=1,padx=20,pady=10)\n",
    "        # Text area 1\n",
    "        merge_lbl = tk.Label(right_frame,text='Merged DF', font=('times new roman', 20, 'bold'),bg='gray20',fg='white')\n",
    "        merge_lbl.grid(row=0,column=0)\n",
    "        merge_text_area1 = scrolledtext.ScrolledText(right_frame, height=31, width=120, wrap=tk.NONE)\n",
    "        merge_text_area1.grid(row=1, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "        merge_horizontal_scrollbar1 = tk.Scrollbar(right_frame, orient=tk.HORIZONTAL, command=merge_text_area1.xview)\n",
    "        merge_horizontal_scrollbar1.grid(row=2, column=0, sticky=\"we\")\n",
    "        merge_text_area1.configure(xscrollcommand=merge_horizontal_scrollbar1.set)\n",
    "\n",
    "        merge_text_area1.delete(1.0, tk.END)  # Clear existing text\n",
    "        merge_text_area1.insert(tk.END, merged_df.head(80).to_string(index=False))\n",
    "    else:\n",
    "        messagebox.showerror(title='Error', message='Files are not loaded!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc75560",
   "metadata": {},
   "source": [
    "# Show Separate DFs for each DAP multiplex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad187a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c18a_df = pd.DataFrame()\n",
    "c18f_df = pd.DataFrame()\n",
    "c188_df = pd.DataFrame()\n",
    "def dab():\n",
    "    global counter\n",
    "    if counter == 1:\n",
    "        global merged_df, c18a_df,c188_df,c18f_df\n",
    "        df1_lbl.destroy()\n",
    "        df2_lbl.destroy()\n",
    "        text_area1.destroy()\n",
    "        text_area2.destroy()\n",
    "        horizontal_scrollbar1.destroy()\n",
    "        horizontal_scrollbar2.destroy()\n",
    "        middle_frame.destroy()\n",
    "\n",
    "        # create frame\n",
    "        # --> Middle Frame\n",
    "        right_frame = tk.LabelFrame(frame,text='',bg='gray20')\n",
    "        right_frame.grid(row=0, column=1,padx=20,pady=10)\n",
    "        # Text area 1\n",
    "        dab_1_lbl = tk.Label(right_frame,text='C18A', font=('times new roman', 20, 'bold'),bg='gray20',fg='white')\n",
    "        dab_1_lbl.grid(row=0,column=0)\n",
    "        dab_1_text_area1 = scrolledtext.ScrolledText(right_frame, height=8, width=120, wrap=tk.NONE)\n",
    "        dab_1_text_area1.grid(row=1, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "        dab_1_horizontal_scrollbar1 = tk.Scrollbar(right_frame, orient=tk.HORIZONTAL, command=dab_1_text_area1.xview)\n",
    "        dab_1_horizontal_scrollbar1.grid(row=2, column=0, sticky=\"we\")\n",
    "        dab_1_text_area1.configure(xscrollcommand=dab_1_horizontal_scrollbar1.set)\n",
    "\n",
    "        # Text area 2\n",
    "        dab_2_lbl = tk.Label(right_frame,text='C18F', font=('times new roman', 20, 'bold'),bg='gray20',fg='white')\n",
    "        dab_2_lbl.grid(row=3,column=0)\n",
    "        dab_2_text_area1 = scrolledtext.ScrolledText(right_frame, height=5, width=120, wrap=tk.NONE)\n",
    "        dab_2_text_area1.grid(row=4, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "        dab_2_horizontal_scrollbar1 = tk.Scrollbar(right_frame, orient=tk.HORIZONTAL, command=dab_2_text_area1.xview)\n",
    "        dab_2_horizontal_scrollbar1.grid(row=5, column=0, sticky=\"we\")\n",
    "        dab_2_text_area1.configure(xscrollcommand=dab_2_horizontal_scrollbar1.set)\n",
    "\n",
    "        # Text area 3\n",
    "        dab_3_lbl = tk.Label(right_frame,text='C188', font=('times new roman', 20, 'bold'),bg='gray20',fg='white')\n",
    "        dab_3_lbl.grid(row=6,column=0)\n",
    "        dab_3_text_area1 = scrolledtext.ScrolledText(right_frame, height=8, width=120, wrap=tk.NONE)\n",
    "        dab_3_text_area1.grid(row=7, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "        dab_3_horizontal_scrollbar1 = tk.Scrollbar(right_frame, orient=tk.HORIZONTAL, command=dab_3_text_area1.xview)\n",
    "        dab_3_horizontal_scrollbar1.grid(row=8, column=0, sticky=\"we\")\n",
    "        dab_3_text_area1.configure(xscrollcommand=dab_3_horizontal_scrollbar1.set)\n",
    "\n",
    "            ## Client requirments: data manipulation and outputs\n",
    "        ### 1. Outputs shouldn't include any data from DAB radio stations that have the following specific NGR (located in TxAntennaDAB.csv(df2)) values\n",
    "        # NGR values to exclude\n",
    "        exclude_NGR = ['NZ02553847', 'SE213515', 'NT05399374', 'NT25265908']\n",
    "\n",
    "        # Filtered rows with specified NGR valuess\n",
    "        merged_df = merged_df[~merged_df['NGR'].isin(exclude_NGR)]\n",
    "\n",
    "        # NGR value exclusion check\n",
    "        NGR_values_to_check = ['NZ02553847', 'SE213515', 'NT05399374', 'NT25265908']\n",
    "        for NGR in NGR_values_to_check:\n",
    "            print(f\"Is {NGR} present in filtered DataFrame? {NGR in merged_df['NGR'].values}\")\n",
    "        ### 2. The ‘EID’ column contains information of the DAB multiplex block E.g C19A. Extract this out into a new column, one for each of the following DAB multiplexes:\n",
    "\n",
    "        # a) all DAB multiplexes, that are , C18A, C18F, C188\n",
    "\n",
    "        # b) join each category, C18A, C18F, C188 to the ‘ NGR’ that signifies the DAB stations location to the following: ‘Site’, ‘Site Height, In-Use Ae Ht, In-Use ERP Total \n",
    "\n",
    "        # Please note that: In-Use Ae Ht, In-Use ERP Total  will need the following new header after extraction: Aerial height(m), Power(kW) respectively.\n",
    "        #print(merged_df.columns)\n",
    "        # To avoid redundancy and increased memory usage create separate DFs for each DAP multiplex category with the relevant columns ONLY\n",
    "\n",
    "        eid_values = ['C18A', 'C18F', 'C188']\n",
    "\n",
    "        # dictionary to store separate dataframes for each EID value\n",
    "        eid_dataframes = {}\n",
    "\n",
    "        for eid in eid_values:\n",
    "            # filter original df 'merged_df' for specified EID values\n",
    "            eid_df = merged_df[merged_df['EID'] == eid][['NGR', 'Site', 'Site Height', 'In-Use Ae Ht', 'In-Use ERP Total', 'Date', 'Freq.', 'Block', 'Serv Label1', 'Serv Label2', 'Serv Label3', 'Serv Label4', 'Serv Label10']]\n",
    "            # rename columns In-Use Ae Ht, In-Use ERP Total to Aerial height(m), Power(kW) respectively\n",
    "            eid_df.rename(columns={'In-Use Ae Ht': 'Aerial height(m)', 'In-Use ERP Total': 'Power(kW)'}, inplace = True)\n",
    "            # store EID dataframe in dictionary\n",
    "            eid_dataframes[eid] = eid_df\n",
    "\n",
    "        # access dataframe for EID C18A\n",
    "        c18a_df = eid_dataframes['C18A']\n",
    "        # access dataframe for EID C18F\n",
    "        c18f_df = eid_dataframes['C18F']\n",
    "\n",
    "        # access dataframe for EID C188\n",
    "        c188_df = eid_dataframes['C188']\n",
    "\n",
    "        dab_1_text_area1.delete(1.0, tk.END)  # Clear existing text\n",
    "        dab_1_text_area1.insert(tk.END, c18a_df.head(20).to_string(index=False))\n",
    "        dab_2_text_area1.delete(1.0, tk.END)  # Clear existing text\n",
    "        dab_2_text_area1.insert(tk.END, c18f_df.head(20).to_string(index=False))\n",
    "        dab_3_text_area1.delete(1.0, tk.END)  # Clear existing text\n",
    "        dab_3_text_area1.insert(tk.END, c188_df.head(20).to_string(index=False))\n",
    "    else:\n",
    "        messagebox.showerror(title='Error', message='Files are not loaded!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "354cb326",
   "metadata": {},
   "source": [
    "# Show Statistic Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f56f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def statistic_tables():\n",
    "    \n",
    "    global counter\n",
    "    if counter == 1:\n",
    "        global c188_df,c18a_df,c18f_df\n",
    "        ### 3. The client initially needs information to generate the following and output the results using appropriate representation:\n",
    "\n",
    "        #    a) Produce the mean, mode and median for the ‘In-Use ERP Total’ from the extracted DAB multiplexes extracted earlier (C18A, C18F, C188) for ‘Site Height’ more than 75\n",
    "        #     (Make sure my code considers anomalies)\n",
    "        #     b) Produce the mean, mode and median for the ‘In-Use ERP Total’ from the extracted DAB multiplexes extracted earlier (C18A, C18F, C188) for ‘Date’ from 2001 onwards\n",
    "        # (Make sure my code considers anomalies)\n",
    "        def calculate_stats(df, column_name, condition_col, condition_value):\n",
    "            filtered_df = df[df[condition_col] > condition_value]\n",
    "            mean = filtered_df[column_name].mean()\n",
    "            median = filtered_df[column_name].median()\n",
    "\n",
    "            max_count = 0\n",
    "            mode_value = None\n",
    "            for num in filtered_df[column_name]:\n",
    "                occurrences = filtered_df[column_name].eq(num).sum()\n",
    "                if occurrences > max_count:\n",
    "                    max_count = occurrences\n",
    "                    mode_value = num\n",
    "\n",
    "            mode = mode_value if max_count > 1 else \"No mode\"\n",
    "            return mean, median, mode\n",
    "        def print_stats_table(title, description, columns, data):\n",
    "            print(title)\n",
    "            print(description)\n",
    "            print(tabulate(data, headers=columns, tablefmt='grid'))\n",
    "            print(\"\\n\")\n",
    "        # Calculate statistics for Site Height using the calculate_stats function\n",
    "        c18a_75h_mean_power, c18a_75h_median_power, c18a_75h_mode_power = calculate_stats(c18a_df, 'Power(kW)', 'Site Height', 75)\n",
    "        c18f_75h_mean_power, c18f_75h_median_power, c18f_75h_mode_power = calculate_stats(c18f_df, 'Power(kW)', 'Site Height', 75)\n",
    "        c188_75h_mean_power, c188_75h_median_power, c188_75h_mode_power = calculate_stats(c188_df, 'Power(kW)', 'Site Height', 75)\n",
    "\n",
    "        # print(\"For C18A Site Heights more than 75:\")\n",
    "        # print(\"Mean Power(kW):\", c18a_75h_mean_power)\n",
    "        # print(\"Median Power(kW):\", c18a_75h_median_power)\n",
    "        # print(\"Mode Power(kW):\", c18a_75h_mode_power)\n",
    "\n",
    "        # print(\"\\nFor C18F Site Heights more than 75:\")\n",
    "        # print(\"Mean Power(kW):\", c18f_75h_mean_power)\n",
    "        # print(\"Median Power(kW):\", c18f_75h_median_power)\n",
    "        # print(\"Mode Power(kW):\", c18f_75h_mode_power)\n",
    "\n",
    "        # print(\"\\nFor C188 Site Heights more than 75:\")\n",
    "        # print(\"Mean Power(kW):\", c188_75h_mean_power)\n",
    "        # print(\"Median Power(kW):\", c188_75h_median_power)\n",
    "        # print(\"Mode Power(kW):\", c188_75h_mode_power)\n",
    "\n",
    "        # Table 1: Site Heights more than 75\n",
    "        table1_title = \"Statistics for Site Heights more than 75\"\n",
    "        table1_description = \"This table shows the mean, median, and mode for DAB Multiplexes C18A, C18F, and C188 that have a Site Height of more than 75.\"\n",
    "        table1_columns = [\"\", \"    Mean\", \"               Median\", \"             Mode\"]\n",
    "        table1_data = [\n",
    "            [\"C18A\", c18a_75h_mean_power, c18a_75h_median_power, c18a_75h_mode_power],\n",
    "            [\"C18F\", c18f_75h_mean_power, c18f_75h_median_power, c18f_75h_mode_power],\n",
    "            [\"C188\", c188_75h_mean_power, c188_75h_median_power, c188_75h_mode_power]\n",
    "        ]\n",
    "\n",
    "        # Print table 1\n",
    "        #print_stats_table(table1_title, table1_description, table1_columns, table1_data)\n",
    "\n",
    "        df1_lbl.destroy()\n",
    "        df2_lbl.destroy()\n",
    "        text_area1.destroy()\n",
    "        text_area2.destroy()\n",
    "        horizontal_scrollbar1.destroy()\n",
    "        horizontal_scrollbar2.destroy()\n",
    "        middle_frame.destroy()\n",
    "\n",
    "        # create frame\n",
    "        # --> Middle Frame\n",
    "        right_frame = tk.LabelFrame(frame,text='',bg='gray20')\n",
    "        right_frame.grid(row=0, column=1,padx=20,pady=10)\n",
    "        # Text area 1\n",
    "        table_1_lbl = tk.Label(right_frame,text=table1_title, font=('times new roman', 20, 'bold'),bg='gray20',fg='white')\n",
    "        table_1_lbl.grid(row=0,column=0)\n",
    "        table_1_text_area1 = scrolledtext.ScrolledText(right_frame, height=31, width=58, wrap=tk.NONE)\n",
    "        table_1_text_area1.grid(row=1, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "        table_1_horizontal_scrollbar1 = tk.Scrollbar(right_frame, orient=tk.HORIZONTAL, command=table_1_text_area1.xview)\n",
    "        table_1_horizontal_scrollbar1.grid(row=2, column=0, sticky=\"we\")\n",
    "        table_1_text_area1.configure(xscrollcommand=table_1_horizontal_scrollbar1.set)\n",
    "        # Construct the text to be displayed in the TextArea\n",
    "        table_text = f\" Title : {table1_title}\\n\\n Description : {table1_description}\\n\\n\"\n",
    "        table_text += \"\\t\".join(table1_columns) + \"\\n\"  # Header\n",
    "        for row in table1_data:\n",
    "            table_text += \"\\t\".join(map(str, row)) + \"\\n\"\n",
    "\n",
    "        # Insert the text into the TextArea\n",
    "        table_1_text_area1.insert(tk.END, table_text)\n",
    "\n",
    "\n",
    "        # Calculate statistics for Date using the calculate_stats function\n",
    "        c18a_01onwards_mean_power, c18a_01onward_median_power, c18a_01onward_mode_power = calculate_stats(c18a_df, 'Power(kW)', 'Date', pd.Timestamp('2001-01-01'))\n",
    "        c18f_01onwards_mean_power, c18f_01onward_median_power, c18f_01onward_mode_power = calculate_stats(c18f_df, 'Power(kW)', 'Date', pd.Timestamp('2001-01-01'))\n",
    "        c188_01onwards_mean_power, c188_01onward_median_power, c188_01onward_mode_power = calculate_stats(c188_df, 'Power(kW)', 'Date', pd.Timestamp('2001-01-01'))\n",
    "\n",
    "        # print(\"\\nFor C18A date 2001 onwards:\")\n",
    "        # print(\"Mean Power(kW):\", c18a_01onwards_mean_power)\n",
    "        # print(\"Median Power(kW):\", c18a_01onward_median_power)\n",
    "        # print(\"Mode Power(kW):\", c18a_01onward_mode_power)\n",
    "\n",
    "        # print(\"\\nFor C18F date 2001 onwards:\")\n",
    "        # print(\"Mean Power(kW):\", c18f_01onwards_mean_power)\n",
    "        # print(\"Median Power(kW):\", c18f_01onward_median_power)\n",
    "        # print(\"Mode Power(kW):\", c18f_01onward_mode_power)\n",
    "\n",
    "        # print(\"\\nFor C188 date 2001 onwards:\")\n",
    "        # print(\"Mean Power(kW):\", c188_01onwards_mean_power)\n",
    "        # print(\"Median Power(kW):\", c188_01onward_median_power)\n",
    "        # print(\"Mode Power(kW):\", c188_01onward_mode_power)\n",
    "\n",
    "        # Table 2: Date 2001 onwards\n",
    "        table2_title = \"Statistics for Date 2001 onwards\"\n",
    "        table2_description = \"This table shows the mean, median, and mode for DAB Multiplexes C18A, C18F, and C188 for dates starting from 2001.\"\n",
    "        table2_columns = [\"\", \"    Mean\", \"   Median\", \"       Mode\"]\n",
    "        table2_data = [\n",
    "            [\"C18A\", c18a_01onwards_mean_power, c18a_01onward_median_power, c18a_01onward_mode_power],\n",
    "            [\"C18F\", c18f_01onwards_mean_power, c18f_01onward_median_power, c18f_01onward_mode_power],\n",
    "            [\"C188\", c188_01onwards_mean_power, c188_01onward_median_power, c188_01onward_mode_power]\n",
    "        ]\n",
    "\n",
    "        table_2_lbl = tk.Label(right_frame,text=table2_title, font=('times new roman', 20, 'bold'),bg='gray20',fg='white')\n",
    "        table_2_lbl.grid(row=0,column=1)\n",
    "        table_2_text_area1 = scrolledtext.ScrolledText(right_frame, height=31, width=58, wrap=tk.NONE)\n",
    "        table_2_text_area1.grid(row=1, column=1, padx=10, pady=10, sticky=\"w\")\n",
    "        table_2_horizontal_scrollbar1 = tk.Scrollbar(right_frame, orient=tk.HORIZONTAL, command=table_2_text_area1.xview)\n",
    "        table_2_horizontal_scrollbar1.grid(row=2, column=1, sticky=\"we\")\n",
    "        table_2_text_area1.configure(xscrollcommand=table_2_horizontal_scrollbar1.set)\n",
    "\n",
    "        # Construct the text to be displayed in the TextArea\n",
    "        table_text_2 = f\" Title : {table2_title}\\n\\n Description : {table2_description}\\n\\n\"\n",
    "        table_text_2 += \"\\t\".join(table2_columns) + \"\\n\"  # Header\n",
    "        for row in table2_data:\n",
    "            table_text_2 += \"\\t\".join(map(str, row)) + \"\\n\"\n",
    "\n",
    "        # Insert the text into the TextArea\n",
    "        table_2_text_area1.insert(tk.END, table_text_2)\n",
    "        # Print Table 2\n",
    "        #print_stats_table(table2_title, table2_description, table2_columns, table2_data)\n",
    "    else:\n",
    "        messagebox.showerror(title='Error', message='Files are not loaded!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f208be2",
   "metadata": {},
   "source": [
    "# Geospatial Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e93cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def graph_1():\n",
    "    \n",
    "    global counter\n",
    "    if counter == 1:\n",
    "        global c188_df,c18a_df,c18f_df,merged_df\n",
    "            # new column to indicate the DF source\n",
    "        c18a_df['DAB Station'] = 'C18A'\n",
    "        c18f_df['DAB Station'] = 'C18F'\n",
    "        c188_df['DAB Station'] = 'C188'\n",
    "\n",
    "        # list of columns to keep/that are necessary for this task\n",
    "        graph_columns = ['DAB Station', 'Freq.', 'Block', 'Serv Label1', 'Serv Label2', 'Serv Label3', 'Serv Label4', 'Serv Label10', 'Site']\n",
    "\n",
    "        # new DF with selected columns from original DFs\n",
    "        c18af8_cols = pd.concat([c18a_df[graph_columns], c18f_df[graph_columns], c188_df[graph_columns]], ignore_index=True)\n",
    "            \n",
    "        c18af8_cols.head()\n",
    "        # extract Long and Lat columns from 'merged_df' for map\n",
    "        long_lat_cols = merged_df[['Site', 'Lat', 'Long']]\n",
    "        long_lat_cols.head()\n",
    "        # check for duplicates\n",
    "        print(long_lat_cols['Site'].duplicated().any())\n",
    "        # remove duplicates\n",
    "        long_lat_cols = long_lat_cols.drop_duplicates(subset='Site')\n",
    "        # merge 'long_lat_cols' DF with 'c18af8_vizualization' DF\n",
    "        c18af8_viz = c18af8_cols.merge(long_lat_cols, on = 'Site', how='left')\n",
    "        c18af8_viz.head()\n",
    "        #%matplotlib notebook\n",
    "\n",
    "        # Create a dictionary to map DAB stations to colors\n",
    "        dab_station_colors = {\n",
    "            'C18A': 'red',\n",
    "            'C18F': 'blue',\n",
    "            'C188': 'purple'\n",
    "        }\n",
    "\n",
    "        # Map DAB stations to colors\n",
    "        c18af8_viz['Color'] = c18af8_viz['DAB Station'].map(dab_station_colors)\n",
    "\n",
    "\n",
    "        # Create the main scatter plot\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        scatter = ax.scatter(c18af8_viz['Long'], c18af8_viz['Lat'], c=c18af8_viz['Color'], s=50, alpha=0.6)\n",
    "        ax.set_xlabel('Longitude')\n",
    "        ax.set_ylabel('Latitude')\n",
    "        ax.set_title('DAB Stations Geospatial Map')\n",
    "\n",
    "        # Add a legend for the color coding\n",
    "        for dab_station, color in dab_station_colors.items():\n",
    "            ax.scatter([], [], c=color, label=dab_station)\n",
    "\n",
    "        ax.legend(scatterpoints=1, frameon=True, labelspacing=1, title='DAB Station', bbox_to_anchor=(1.03, 1.02), loc='upper left')\n",
    "\n",
    "        ax.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "\n",
    "        # Placeholder for the annotation (initially not visible)\n",
    "        annotation = ax.annotate('', xy=(0,0), xytext=(0,10), textcoords='offset points',\n",
    "                                bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"aliceblue\"),\n",
    "                                arrowprops=dict(facecolor='black', arrowstyle=\"->\"),\n",
    "                                visible=False)\n",
    "\n",
    "        # Function to update and display annotation when a point is clicked\n",
    "        def on_click(event):\n",
    "            cont, ind = scatter.contains(event)\n",
    "            if cont:\n",
    "                station = c18af8_viz.iloc[ind[\"ind\"][0]]\n",
    "                details = f\"Site: {station['Site']}\\nDAB: {station['DAB Station']}\\nFreq: {station['Freq.']}\\nBlock: {station['Block']}\"\n",
    "                annotation.set_text(details)\n",
    "                annotation.set_position((event.xdata, event.ydata))\n",
    "                annotation.xy = (event.xdata, event.ydata)\n",
    "                annotation.set_visible(True)\n",
    "            else:\n",
    "                annotation.set_visible(False)\n",
    "            fig.canvas.draw_idle()\n",
    "\n",
    "        # Connect the click event to our function\n",
    "        fig.canvas.mpl_connect('motion_notify_event', on_click)\n",
    "\n",
    "        # --\n",
    "        df1_lbl.destroy()\n",
    "        df2_lbl.destroy()\n",
    "        text_area1.destroy()\n",
    "        text_area2.destroy()\n",
    "        horizontal_scrollbar1.destroy()\n",
    "        horizontal_scrollbar2.destroy()\n",
    "        middle_frame.destroy()\n",
    "\n",
    "        # create frame\n",
    "        # --> Top level window\n",
    "        top_level = tk.Toplevel(window)\n",
    "        top_level.title(\"Geospatial Map\")\n",
    "\n",
    "        canvas = FigureCanvasTkAgg(fig, master=top_level)\n",
    "        canvas_widget = canvas.get_tk_widget()\n",
    "        canvas_widget.pack(fill=tk.BOTH, expand=True)  # Fill the entire window\n",
    "        canvas_widget.update_idletasks()  # Update widget\n",
    "\n",
    "        # Add horizontal and vertical scrollbars\n",
    "        h_scrollbar = tk.Scrollbar(top_level, orient=tk.HORIZONTAL)\n",
    "        h_scrollbar.pack(side=tk.BOTTOM, fill=tk.X)\n",
    "        h_scrollbar.config(command=canvas_widget.xview)\n",
    "\n",
    "        v_scrollbar = tk.Scrollbar(top_level, orient=tk.VERTICAL)\n",
    "        v_scrollbar.pack(side=tk.RIGHT, fill=tk.Y)\n",
    "        v_scrollbar.config(command=canvas_widget.yview)\n",
    "\n",
    "        # Configure the canvas to use the scrollbars\n",
    "        canvas_widget.config(xscrollcommand=h_scrollbar.set, yscrollcommand=v_scrollbar.set)\n",
    "\n",
    "    else:\n",
    "        messagebox.showerror(title='Error', message='Files are not loaded!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d60eaf",
   "metadata": {},
   "source": [
    "# Correlation Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ed3e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def correlation():\n",
    "    \n",
    "    global counter\n",
    "    if counter == 1:\n",
    "        # new column to indicate the DF source\n",
    "        global c188_df,c18a_df,c18f_df,merged_df\n",
    "        c18a_df['DAB Station'] = 'C18A'\n",
    "        c18f_df['DAB Station'] = 'C18F'\n",
    "        c188_df['DAB Station'] = 'C188'\n",
    "\n",
    "        # list of columns to keep/that are necessary for this task\n",
    "        correlation_columns = ['Freq.', 'Block', 'Serv Label1', 'Serv Label2', 'Serv Label3', 'Serv Label4', 'Serv Label10']\n",
    "\n",
    "        # new DF with selected columns from original DFs\n",
    "        correlation_c18af8 = pd.concat([c18a_df[correlation_columns], c18f_df[correlation_columns], c188_df[correlation_columns]], ignore_index=True)\n",
    "            \n",
    "        correlation_c18af8.head(20)\n",
    "        # One-hot encode categorical columns\n",
    "        one_hot_df = pd.get_dummies(correlation_c18af8, columns=['Freq.', 'Block', 'Serv Label1', 'Serv Label2', 'Serv Label3', 'Serv Label4', 'Serv Label10'])\n",
    "\n",
    "        # Calculate the correlation matrix\n",
    "        correlation_matrix = one_hot_df.corr()\n",
    "        correlation_matrix\n",
    "        # Visualize the correlation matrix using a heatmap\n",
    "        figure = plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(correlation_matrix, cmap='coolwarm', annot=True, square=True, )\n",
    "        plt.title(\"C18A, C18F, and C188 DAB Stations Correlation Heatmap\")\n",
    "\n",
    "        top = tk.Toplevel(window)\n",
    "        top.title(\"Correlation Heat Map\")\n",
    "        canvas = FigureCanvasTkAgg(figure, master=top)\n",
    "        canvas.get_tk_widget().pack()\n",
    "    \n",
    "    else:\n",
    "        messagebox.showerror(title='Error', message='Files are not loaded!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32913e24",
   "metadata": {},
   "source": [
    "# GUI Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeae493e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Header Label\n",
    "header_lbl = tk.Label(window, text='Data Analysis System', font=('times new roman', 30, 'bold'),\n",
    "                      fg='gold', bg='gray20', bd=12, relief='ridge')\n",
    "header_lbl.pack(fill='x')\n",
    "\n",
    "# Create GUI elements\n",
    "frame = tk.Frame(window,bg='gray20')\n",
    "frame.pack()\n",
    "\n",
    "# --> Left frame \n",
    "left_frame = tk.LabelFrame(frame, text='Menue',fg='gold',bg='gray20',font=('times new roman',15,'bold'))\n",
    "left_frame.grid(column=0, row=0,rowspan=2)\n",
    "\n",
    "load_btn = tk.Button(left_frame, text='Load Files', command=load_csv_files,font=(\"Helvetica\", 12, \"bold\"),width=18,\n",
    "    pady=5,borderwidth=0,activebackground=\"#3BC1AC\",bg='#008080',fg='white')\n",
    "load_btn.grid(column=0, row=0,padx=40,pady=(25,10))\n",
    "\n",
    "display_btn = tk.Button(left_frame, text='Display Files', command=display_files,font=(\"Helvetica\", 12, \"bold\"),width=18,\n",
    "    pady=5,borderwidth=0,activebackground=\"#3BC1AC\",bg='#008080',fg='white')\n",
    "display_btn.grid(column=0, row=1,padx=20,pady=(13,10))\n",
    "\n",
    "clean_btn = tk.Button(left_frame, text='Cleaned Data', command=clean_data,font=(\"Helvetica\", 12, \"bold\"),width=18,\n",
    "    pady=5,borderwidth=0,activebackground=\"#3BC1AC\",bg='#008080',fg='white')\n",
    "clean_btn.grid(column=0, row=2,padx=20,pady=(13,10))\n",
    "\n",
    "\n",
    "\n",
    "merged_btn = tk.Button(left_frame, text='Merged Data', command=merge_data,font=(\"Helvetica\", 12, \"bold\"),width=18,\n",
    "    pady=5,borderwidth=0,activebackground=\"#3BC1AC\",bg='#008080',fg='white')\n",
    "merged_btn.grid(column=0, row=3,padx=20,pady=(13,10))\n",
    "\n",
    "dab_btn = tk.Button(left_frame, text='DAB Multiplexes', command=dab,font=(\"Helvetica\", 12, \"bold\"),width=18,\n",
    "    pady=5,borderwidth=0,activebackground=\"#3BC1AC\",bg='#008080',fg='white')\n",
    "dab_btn.grid(column=0, row=4,padx=20,pady=(13,10))\n",
    "\n",
    "\n",
    "statistic_btn = tk.Button(left_frame, text='Statistic Tables', command=statistic_tables,font=(\"Helvetica\", 12, \"bold\"),width=18,\n",
    "    pady=5,borderwidth=0,activebackground=\"#3BC1AC\",bg='#008080',fg='white')\n",
    "statistic_btn.grid(column=0, row=5,padx=20,pady=(13,10))\n",
    "\n",
    "\n",
    "\n",
    "graph_1_btn = tk.Button(left_frame, text='Geospatial Map', command=graph_1,font=(\"Helvetica\", 12, \"bold\"),width=18,\n",
    "    pady=5,borderwidth=0,activebackground=\"#3BC1AC\",bg='#008080',fg='white')\n",
    "graph_1_btn.grid(column=0, row=6,padx=20,pady=(13,10))\n",
    "\n",
    "correlation_graph_btn = tk.Button(left_frame, text='Correlation Heat Map', command=correlation,font=(\"Helvetica\", 12, \"bold\"),width=18,\n",
    "    pady=5,borderwidth=0,activebackground=\"#3BC1AC\",bg='#008080',fg='white')\n",
    "correlation_graph_btn.grid(column=0, row=7,padx=20,pady=(13,10))\n",
    "\n",
    "\n",
    "sep = ttk.Separator(left_frame)\n",
    "sep.grid(row=8,column=0,padx=(10,10),pady=10,sticky='ew')\n",
    "def exitt():\n",
    "    window.destroy()\n",
    "\n",
    "exit_btn = tk.Button(left_frame,command=exitt,text='Exit',fg='black',width=10,bg='white',bd=5,font=('times new roman',12,'bold'))\n",
    "exit_btn.grid(row=9,column=0,pady=10)\n",
    "\n",
    "# --> Middle Frame\n",
    "middle_frame = tk.LabelFrame(frame,text='',bg='gray20')\n",
    "middle_frame.grid(row=0, column=1,padx=20,pady=10)\n",
    "\n",
    "# Text area 1\n",
    "df1_lbl = tk.Label(middle_frame,text='Df-1 (TxParamsDAB)', font=('times new roman', 20, 'bold'),bg='gray20',fg='white')\n",
    "df1_lbl.grid(row=0,column=0)\n",
    "text_area1 = scrolledtext.ScrolledText(middle_frame, height=13, width=120, wrap=tk.NONE)\n",
    "text_area1.grid(row=1, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "horizontal_scrollbar1 = tk.Scrollbar(middle_frame, orient=tk.HORIZONTAL, command=text_area1.xview)\n",
    "horizontal_scrollbar1.grid(row=2, column=0, sticky=\"we\")\n",
    "text_area1.configure(xscrollcommand=horizontal_scrollbar1.set)\n",
    "\n",
    "# Text area 2\n",
    "df2_lbl = tk.Label(middle_frame,text='Df-2 (TxAntennaDAB)', font=('times new roman', 20, 'bold'),bg='gray20',fg='white')\n",
    "df2_lbl.grid(row=3,column=0)\n",
    "text_area2 = scrolledtext.ScrolledText(middle_frame, height=13, width=120, wrap=tk.NONE)\n",
    "text_area2.grid(row=4, column=0, padx=10, pady=10, sticky=\"w\")\n",
    "horizontal_scrollbar2 = tk.Scrollbar(middle_frame, orient=tk.HORIZONTAL, command=text_area2.xview)\n",
    "horizontal_scrollbar2.grid(row=5, column=0, sticky=\"we\")\n",
    "text_area2.configure(xscrollcommand=horizontal_scrollbar2.set)\n",
    "\n",
    "\n",
    "\n",
    "window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
